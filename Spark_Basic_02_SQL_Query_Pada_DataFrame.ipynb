{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "SQL adalah salah satu bahasa populer untuk pemrosesan dan analisis data. Spark mendukung SQL untuk memproses DataFrame.\n",
        "\n",
        "Kita akan menggunakan data yang sama dengan yg digunakan pada bab eksplorasi DataFrame.\n"
      ],
      "metadata": {
        "id": "vJbZRSkkTnAw"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xyqGzlLOuBpV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8db700a3-5a01-4cff-dfd5-14cedc30d292"
      },
      "source": [
        "%pip install pyspark"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.10/dist-packages (3.5.0)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.10/dist-packages (from pyspark) (0.10.9.7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qJDNbI5gti9B"
      },
      "source": [
        "import pyspark\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql import functions as F"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inisialisasi spark session untuk berinteraksi dengan Spark cluster"
      ],
      "metadata": {
        "id": "HgEv2iNhTitC"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hnxed8rpt5Xs"
      },
      "source": [
        "spark = SparkSession.builder.appName('DataFrame Basics').getOrCreate()"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download dataset"
      ],
      "metadata": {
        "id": "iHGCn-voUTzn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!wget https://raw.githubusercontent.com/urfie/SparkSQL-dengan-Hive/main/datasets/indonesia2013-2015.csv\n",
        "!wget https://github.com/urfie/SparkSQL-dengan-Hive/raw/main/datasets/application_record_header.csv.gz"
      ],
      "metadata": {
        "id": "PQTqnwezHtSq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b10fcac7-d661-4c96-bc8a-c2ca6ac19b76"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-06 17:29:03--  https://github.com/urfie/SparkSQL-dengan-Hive/raw/main/datasets/application_record_header.csv.gz\n",
            "Resolving github.com (github.com)... 140.82.114.4\n",
            "Connecting to github.com (github.com)|140.82.114.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/urfie/SparkSQL-dengan-Hive/main/datasets/application_record_header.csv.gz [following]\n",
            "--2023-10-06 17:29:04--  https://raw.githubusercontent.com/urfie/SparkSQL-dengan-Hive/main/datasets/application_record_header.csv.gz\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3175443 (3.0M) [application/octet-stream]\n",
            "Saving to: ‘application_record_header.csv.gz.1’\n",
            "\n",
            "application_record_ 100%[===================>]   3.03M  --.-KB/s    in 0.01s   \n",
            "\n",
            "2023-10-06 17:29:04 (249 MB/s) - ‘application_record_header.csv.gz.1’ saved [3175443/3175443]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load ke dataframe"
      ],
      "metadata": {
        "id": "-vEl7qY6UV4Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = spark.read.csv(\"application_record_header.csv.gz\", header=True, inferSchema=True)"
      ],
      "metadata": {
        "id": "ArREYTQWHy3J"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sebelum menggunakan SQL, kita perlu membuat temporary table dari dataframe yang akan kita olah.\n",
        "\n",
        "Gunakan fungsi `createOrReplaceTempView(nama_tabel)` pada dataframe tersebut."
      ],
      "metadata": {
        "id": "lvgyM2iKUYS9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df.createOrReplaceTempView(\"app_record\")"
      ],
      "metadata": {
        "id": "29qI_YUJnF_N"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Selanjutnya kita bisa menggunakan nama tabel yang sudah kita definisikan dalam SQL statement.\n",
        "\n",
        "Untuk mengeksekusi SQL statement, kita gunakan fungsi `sql(sqlstatement)` pada spark session."
      ],
      "metadata": {
        "id": "xuijaPcEUz3g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select count(*) from app_record\").show()"
      ],
      "metadata": {
        "id": "mEZWLQbtnIHX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b42fefee-416b-44fb-ada7-a35dff9ac7ad"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------+\n",
            "|count(1)|\n",
            "+--------+\n",
            "|  438557|\n",
            "+--------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select * from app_record limit 5\").show()"
      ],
      "metadata": {
        "id": "6fLoE47EnMtP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f57b491c-d817-4fdb-f89d-043e43584e25"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
            "|     ID|CODE_GENDER|FLAG_OWN_CAR|FLAG_OWN_REALTY|CNT_CHILDREN|AMT_INCOME_TOTAL|    NAME_INCOME_TYPE| NAME_EDUCATION_TYPE|  NAME_FAMILY_STATUS|NAME_HOUSING_TYPE|DAYS_BIRTH|DAYS_EMPLOYED|FLAG_MOBIL|FLAG_WORK_PHONE|FLAG_PHONE|FLAG_EMAIL|OCCUPATION_TYPE|CNT_FAM_MEMBERS|\n",
            "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
            "|5008804|          M|           Y|              Y|           0|        427500.0|             Working|    Higher education|      Civil marriage| Rented apartment|    -12005|        -4542|         1|              1|         0|         0|           NULL|            2.0|\n",
            "|5008805|          M|           Y|              Y|           0|        427500.0|             Working|    Higher education|      Civil marriage| Rented apartment|    -12005|        -4542|         1|              1|         0|         0|           NULL|            2.0|\n",
            "|5008806|          M|           Y|              Y|           0|        112500.0|             Working|Secondary / secon...|             Married|House / apartment|    -21474|        -1134|         1|              0|         0|         0| Security staff|            2.0|\n",
            "|5008808|          F|           N|              Y|           0|        270000.0|Commercial associate|Secondary / secon...|Single / not married|House / apartment|    -19110|        -3051|         1|              0|         1|         1|    Sales staff|            1.0|\n",
            "|5008809|          F|           N|              Y|           0|        270000.0|Commercial associate|Secondary / secon...|Single / not married|House / apartment|    -19110|        -3051|         1|              0|         1|         1|    Sales staff|            1.0|\n",
            "+-------+-----------+------------+---------------+------------+----------------+--------------------+--------------------+--------------------+-----------------+----------+-------------+----------+---------------+----------+----------+---------------+---------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"select distinct NAME_EDUCATION_TYPE from app_record\").show(truncate = False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xbCMW4oP7JbI",
        "outputId": "171af78d-d96d-4999-cb52-611afc35efa3"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------------------------+\n",
            "|NAME_EDUCATION_TYPE          |\n",
            "+-----------------------------+\n",
            "|Academic degree              |\n",
            "|Incomplete higher            |\n",
            "|Secondary / secondary special|\n",
            "|Lower secondary              |\n",
            "|Higher education             |\n",
            "+-----------------------------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mydata = (('Academic degree',3),\n",
        "    ('Incomplete higher',4),\n",
        "    ('Secondary / secondary special',2),\n",
        "    ('Lower secondary',1),\n",
        "    ('Higher education',5))\n",
        "\n",
        "ref_edu = spark.createDataFrame(mydata).toDF(\"NAME_EDUCATION_TYPE\", \"EDU_LEVEL\")\n",
        "ref_edu.createOrReplaceTempView(\"ref_edu\")\n",
        "spark.sql(\"select * from ref_edu\").show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "py7cZ3yF7INt",
        "outputId": "64dd343f-c15c-4b0b-9824-59ad6e9ec2df"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+---------+\n",
            "| NAME_EDUCATION_TYPE|EDU_LEVEL|\n",
            "+--------------------+---------+\n",
            "|     Academic degree|        3|\n",
            "|   Incomplete higher|        4|\n",
            "|Secondary / secon...|        2|\n",
            "|     Lower secondary|        1|\n",
            "|    Higher education|        5|\n",
            "+--------------------+---------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark.sql(\"\"\"SELECT edu_level, count(1) FROM\n",
        "              (SELECT ref_edu.EDU_LEVEL as edu_level\n",
        "                FROM app_record LEFT JOIN ref_edu\n",
        "                ON app_record.NAME_EDUCATION_TYPE=ref_edu.NAME_EDUCATION_TYPE)\n",
        "             GROUP BY edu_level SORT BY edu_level\"\"\").write.saveAsTable(name=\"aggregated_edu\", mode=\"overwrite\")"
      ],
      "metadata": {
        "id": "IkuuNd0ynWll"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ysuMyldWC59p"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}